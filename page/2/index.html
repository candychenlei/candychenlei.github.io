<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Pokemonlei的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="陈磊的博客 | pokemonlei">
<meta property="og:type" content="website">
<meta property="og:title" content="Pokemonlei的博客">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Pokemonlei的博客">
<meta property="og:description" content="陈磊的博客 | pokemonlei">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="pokemonlei">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Pokemonlei的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://avatars0.githubusercontent.com/u/20333903?v=3&amp;s=460">
    <h2 class="author">pokemonlei</h2>
    <h3 class="description">陈磊的博客 | pokemonlei</h3>
    <div class="count-box">
      <a href="/archives"><div><strong>14</strong><br>文章</div></a>
      <a href="/categories"><div><strong>7</strong><br>分类</div></a>
      <a href="/tags"><div><strong>13</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-python与机器学习入门一" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/" class="article-date">
  <time class="post-time" datetime="2020-01-11T09:35:46.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/">python与机器学习入门一</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="为什么要写本文"><a href="#为什么要写本文" class="headerlink" title="为什么要写本文"></a>为什么要写本文</h1><p>机器学习涉及到很多数学相关基础知识，概率论，高数算法等，而直接去看这些课本或书籍，简直就是晦涩难懂，哪怕是西瓜书这种通俗易懂的书籍，对于数学不好的人来讲也有点像天书。为了让小白可以较轻松的掌握一些机器学习相关知识，还是要从案例出发，通过案例来学习用到的数学知识，熟悉各种算法的原理，顺便将用到的库和框架进行简单介绍，而且可以结合场景解决实际问题，提高初学者幸福感。<br>不过在此还是要列举一些书籍可供参考：</p>
<ul>
<li>概率论和高数，直接大学课本就好</li>
<li>《机器学习》：俗称西瓜书，学习机器学习的经典书籍</li>
<li>《Python数据分析与挖掘实战》：从数据挖掘的应用出发，以电力、航空、医疗、互联网、生产制造以及公共服务等行业真实案例为主线，深入浅出介绍Python数据挖掘建模过程，实践性极强。 </li>
<li>《TensorFlow技术解析与实战》：包揽TensorFlow1.1的新特性 人脸识别 语音识别 图像和语音相结合等热点一应俱全</li>
</ul>
<h1 id="机器学习是什么"><a href="#机器学习是什么" class="headerlink" title="机器学习是什么"></a>机器学习是什么</h1><blockquote>
<p>机器学习是人工智能的一个分支。机器学习算法是一类从<strong>数据</strong>中自动分析获得<strong>规律</strong>，并利用规律对未知数据进行<strong>预测</strong>的算法。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。 它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。</p>
</blockquote>
<p>机器学习应用在哪些方面？</p>
<blockquote>
<p>维基百科：机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。<br>新闻等应用上的推荐类功能,人脸识别相关功能：直播时的美颜、加装饰等等；<br>这里有一个集合，最具价值的50个机器学习应用[2017年]：<a href="https://bigquant.com/community/t/topic/6909" target="_blank" rel="noopener">https://bigquant.com/community/t/topic/6909</a></p>
</blockquote>
<h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>python深度学习中，读取数据一般是通过pandas读取文件，之所以不读取数据库，是因为数据库读取速度会成为性能瓶颈。</p>
<p>可用数据集：</p>
<ul>
<li>Kaggle：1、大数据竞赛平台，真实数据，数据量巨大</li>
<li>UCI：1，覆盖科学、生活、经济等领域</li>
<li>scikit-learn：数据量小，方便学习</li>
</ul>
<p>常用数据集结构：特征值+目标值<br>注：有些数据可以没有目标值<br>数据中对于特征的处理：</p>
<ul>
<li>pandas：一个数据读取非常方便以及基本的处理格式的工具</li>
<li>对于<strong>特征的处理</strong>提供了强大的接口</li>
</ul>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>什么是特征工程（目的）</p>
<blockquote>
<p>一句话：特征工程是将<strong>原始数据转换为更好的代表预测模型的潜在问题的特征</strong>的过程，从而提高了对未知数据的预测准确性。<br> “数据决定了机器学习的上限，而算法只是尽可能逼近这个上限”，这里的数据指的就是经过特征工程得到的数据。特征工程指的是把原始数据转变为模型的训练数据的过程，它的目的就是获取更好的训练数据特征，使得机器学习模型逼近这个上限。特征工程能使得模型的性能得到提升，有时甚至在简单的模型上也能取得不错的效果。特征工程在机器学习中占有非常重要的作用，一般认为括特征构建、特征提取、特征选择三个部分。特征构建比较麻烦，需要一定的经验。 特征提取与特征选择都是为了从原始特征中找出最有效的特征。它们之间的区别是特征提取强调通过特征转换的方式得到一组具有明显物理或统计意义的特征；而特征选择是从特征集合中挑选一组具有明显物理或统计意义的特征子集。两者都能帮助减少特征的维度、数据冗余，特征提取有时能发现更有意义的特征属性，特征选择的过程经常能表示出每个特征的重要性对于模型构建的重要性。<br>特征工程的目的是筛选出更好的特征，获取更好的训练数据.</p>
</blockquote>
<p>特征工程流程：</p>
<ul>
<li><ol>
<li>数据采集 / 清洗 / 采样<ul>
<li>1.1:数据采集：数据采集前需要明确采集哪些数据，一般的思路为：哪些数据对最后的结果预测有帮助？数据我们能够采集到吗？线上实时计算的时候获取是否快捷？ </li>
<li>1.2:数据清洗： 数据清洗也是很重要的一步，机器学习算法大多数时候就是一个加工机器，至于最后的产品如何，取决于原材料的好坏。数据清洗就是要去除脏数据，比如某些商品的刷单数据。 </li>
<li>1.3:数据采样：采集、清洗过数据以后，正负样本是不均衡的，要进行数据采样。采样的方法有随机采样和分层抽样。但是随机采样会有隐患，因为可能某次随机采样得到的数据很不均匀，更多的是根据特征采用分层抽样。　　</li>
</ul>
</li>
</ol>
</li>
<li>2.特征处理<ul>
<li>2.1:数值型<ul>
<li>幅度调整/归一化：python中会有一些函数比如preprocessing.MinMaxScaler()将幅度调整到 [0,1] 区间。</li>
<li>统计值：包括max, min, mean, std等。python中用pandas库序列化数据后，可以得到数据的统计值。 </li>
</ul>
</li>
<li>2.2:类别型,类别型一般是文本信息，比如颜色是红色、黄色还是蓝色，我们存储数据的时候就需要先处理数据<ul>
<li>one-hot编码，编码后得到哑变量。统计这个特征上有多少类，就设置几维的向量，pd.get_dummies()可以进行one-hot编码。</li>
<li>Hash编码成词向量</li>
<li>Histogram映射：把每一列的特征拿出来，根据target内容做统计，把target中的每个内容对应的百分比填到对应的向量的位置。优点是把两个特征联系起来。 </li>
</ul>
</li>
<li>2.3:时间型<ul>
<li>连续值</li>
<li>离散值</li>
</ul>
</li>
<li>2.4:文本型<ul>
<li>词袋：文本数据预处理后，去掉停用词，剩下的词组成的list，在词库中的映射稀疏向量。Python中用CountVectorizer处理词袋． </li>
<li>把词袋中的词扩充到n-gram：n-gram代表n个词的组合。</li>
</ul>
</li>
<li>2.5:统计型<ul>
<li>加减平均,商品价格高于平均价格多少，用户在某个品类下消费超过平均用户多少，用户连续登录天数超过平均多少…</li>
<li>分位线,商品属于售出商品价格的多少分位线处</li>
<li>次序型</li>
<li>比例类</li>
</ul>
</li>
<li>2.6:组合特征<ul>
<li>拼接型</li>
<li>模型特征组合</li>
</ul>
</li>
</ul>
</li>
<li>3.特征选择:特征选择，就是从多个特征中，挑选出一些对结果预测最有用的特征。特征选择和降维有什么区别呢？前者只踢掉原本特征里和结果预测关系不大的， 后者做特征的计算组合构成新特征。<br>  3.1:过滤型,评估单个特征和结果值之间的相关程度， 排序留下Top相关的特征部分。<br>  3.2:包裹型,把特征选择看做一个特征子集搜索问题， 筛选各种特征子集， 用模型评估效果。 典型算法：“递归特征删除算法”。<br>  3.3:嵌入型,根据模型来分析特征的重要性，最常见的方式为用正则化方式来做特征选择。</li>
</ul>
<h3 id="scikit-learn工具"><a href="#scikit-learn工具" class="headerlink" title="scikit-learn工具"></a>scikit-learn工具</h3><ul>
<li>Python语言的机器学习工具基于Numpy和Scipy</li>
<li>提供了大量用于数据挖掘和分析的工具，包括数据预处理、交叉验证、算法与可视化算法等一系列接口。</li>
<li>文档完善，容易上手</li>
</ul>
<h3 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h3><p>API：sklearn.feature_extraction</p>
<p>字典特征数据抽取：把字典中一些<strong>类别</strong>数据，转换为特征值，如One-hot编码形势。</p>
<ul>
<li>DictVectorizer</li>
</ul>
<p>文本特征抽取：对文本数据进行特征值化<br>文本抽取默认不会对中文进行分词，而是按照空格逗号等进行分。所以在fit_transform之前要进行分词。</p>
<ul>
<li>CountVectorizer:简单的频率统计</li>
<li>TfidfVectorizer：tf-idf算法<ul>
<li>在将文本分词并向量化后，我们可以得到词汇表中每个词在各个文本中形成的词向量，但是这时候的词向量里，有一些类似”to”,”my”,”is”的词，出现的频率可能会高于文章的中心词汇，如果我们的向量化特征仅仅用词频表示就无法反应这一点。因此我们需要进一步的预处理来反应文本的这个特征，而这个预处理就是TF-IDF。</li>
<li>TF-IDF是Term Frequency -  Inverse Document Frequency的缩写，即“词频-逆文本频率”。它由两部分组成，TF和IDF。<ul>
<li>TF也就是词频，我们做的向量化也就是做了文本中各个词的出现频率统计。<blockquote>
<p>词频（TF） = 某个词在文章中的出现次数<br>词频（TF） = 某个词在文章中的出现次数 / 文章总词数。这里是因为文章有长短之分，为了便于不同文章的比较,做”词频”标准化.</p>
</blockquote>
</li>
<li>IDF，即“逆文本频率”，IDF反应了一个词在所有文本中出现的频率，如果一个词在很多的文本中出现，那么它的IDF值应该低，比如上文中的“to”。而反过来如果一个词在比较少的文本中出现，那么它的IDF值应该高。比如一些专业的名词<blockquote>
<p>逆文档频率（IDF） = log（语料库的文档总数/包含该词的文档总数+1）</p>
</blockquote>
</li>
</ul>
</li>
<li>TF-IDF = 词频（TF) * 逆文档频率（IDF）,TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。</li>
</ul>
</li>
</ul>
<p>特征抽取简单demo及API如下：</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction import DictVectorizer</span><br><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line"></span><br><span class="line">def dictvec():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    字典数据抽取</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    # 实例化</span><br><span class="line">    dict &#x3D; DictVectorizer(sparse&#x3D;False)  # sparse指定fit_transform的结果是否转换为sparse矩阵,False的话则不是sparse矩阵而是数组形势</span><br><span class="line">    # 调用fit_transform</span><br><span class="line">    data &#x3D; dict.fit_transform(</span><br><span class="line">        [&#123;&#39;city&#39;: &#39;北京&#39;, &#39;temperature&#39;: 100&#125;, &#123;&#39;city&#39;: &#39;上海&#39;, &#39;temperature&#39;: 60&#125;, &#123;&#39;city&#39;: &#39;深圳&#39;, &#39;temperature&#39;: 30&#125;])     #参数是列表</span><br><span class="line">    print(data)</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    sparse &#x3D; False情况下,这也叫 One-hot编码：</span><br><span class="line">    [[  0.   1.   0. 100.]</span><br><span class="line">    [  1.   0.   0.  60.]</span><br><span class="line">    [  0.   0.   1.  30.]]</span><br><span class="line">    sparse默认为true情况下：</span><br><span class="line">    (0, 1)	1.0</span><br><span class="line">    (0, 3)	100.0</span><br><span class="line">    (1, 0)	1.0</span><br><span class="line">    (1, 3)	60.0</span><br><span class="line">    (2, 2)	1.0</span><br><span class="line">    (2, 3)	30.0</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    print(dict.get_feature_names())  # 返回类别名称，如这里：[&#39;city&#x3D;上海&#39;,&#39;city&#x3D;北京&#39;,&#39;city&#x3D;深圳&#39;,&#39;temperature&#39;]</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">def countvec():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    对文本进行特征值化</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    cv &#x3D; CountVectorizer()  #这里没有sparse参数，后续如果要转换为数组，则要用fit_transform产生的sparse矩阵调用toarray()函数</span><br><span class="line">    data &#x3D; cv.fit_transform([&quot;To the world \\u9752\\u9752 may be just one person&quot;,&quot; To me \\u9752\\u9752 may be the world&quot;])     # 参数是列表</span><br><span class="line"></span><br><span class="line">    print(cv.get_feature_names())</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    统计所有词，单个的英文字母不会统计，比如‘i’，结果为：</span><br><span class="line">    [&#39;be&#39;, &#39;just&#39;, &#39;may&#39;, &#39;me&#39;, &#39;one&#39;, &#39;person&#39;, &#39;the&#39;, &#39;to&#39;, &#39;u9752&#39;, &#39;world&#39;]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    print(data.toarray())</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    对应词出现次数</span><br><span class="line">    [[1 1 1 0 1 1 1 1 2 1]</span><br><span class="line">    [1 0 1 1 0 0 1 1 2 1]]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    # dictvec()</span><br><span class="line">    countvec()</span><br></pre></td></tr></table></figure>


<h3 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h3><p>通过特定的统计方法讲数据转换为算法要求的数据。</p>
<blockquote>
<p>sklearn.preprocessing</p>
</blockquote>
<ul>
<li>归一化，防止某个数据对结果影响太大 sklearn.preprocessing.MinMaxScaler<ul>
<li>通过将原始数据进行变换，把原始数据映射到[0,1]之间</li>
<li>原理：作用于每一列，max为一列的最大值，min为一列的最小值<img src="/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/sklearn%E5%BD%92%E4%B8%80%E5%8C%96%E5%85%AC%E5%BC%8F.jpg" class="" title="sklearn归一化公式"> </li>
<li>缺点：异常点对此影响较大，这种情况下要使用标准化来解决</li>
</ul>
</li>
<li>标准化，异常值影响较小 sklearn.preprocessing.StandardScaler<ul>
<li>通过对原始数据进行变换，把数据变换到<strong>均值为0，标准差为1</strong>的范围内</li>
<li>在已有样本足够多的情况下比较稳定，适合现代嘈杂的大数据场景</li>
<li>原理：<img src="/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/sklearn%E6%A0%87%E5%87%86%E5%8C%96%E5%85%AC%E5%BC%8F.jpg" class="" title="sklearn标准化公式"></li>
</ul>
</li>
</ul>
<p>归一化与标准化示例如下：</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler,StandardScaler</span><br><span class="line"></span><br><span class="line">def mm():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    归一化处理</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    mm &#x3D; MinMaxScaler(feature_range&#x3D;(0,1))  #参数可以指定归一化后的范围，默认为[0,1]</span><br><span class="line">    data &#x3D; mm.fit_transform([[10,2,5,40],[20,4,5,8],[30,6,5,5]])</span><br><span class="line">    print(data)</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    归一化是按照列来归一的</span><br><span class="line">    [[0.         0.         0.         1.        ]</span><br><span class="line">    [0.5        0.5        0.         0.08571429]</span><br><span class="line">    [1.         1.         0.         0.        ]]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">def stand():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    标准化缩放</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    std &#x3D; StandardScaler()</span><br><span class="line">    data &#x3D; std.fit_transform([[1,-1,3],[2,4,2],[4,6,-1]])</span><br><span class="line">    print(data)</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    转换后的值，每一列均值为0，标准差为1</span><br><span class="line">    [[-1.06904497 -1.35873244  0.98058068]</span><br><span class="line">    [-0.26726124  0.33968311  0.39223227]</span><br><span class="line">    [ 1.33630621  1.01904933 -1.37281295]]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    #mm()</span><br><span class="line">    stand()</span><br></pre></td></tr></table></figure>

<h3 id="数据降维"><a href="#数据降维" class="headerlink" title="数据降维"></a>数据降维</h3><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>特征选择原因：如果训练数据包含许多<strong>冗余</strong>或<strong>无关</strong>特征，因而移除这些特征并不会导致丢失信息</p>
<ul>
<li>数据冗余：部分特征相关度高，容易消耗计算机性能</li>
<li>缩短训练时间</li>
<li>改善通用性、降低过拟合</li>
</ul>
<p>特征选择是什么？</p>
<blockquote>
<p>特征选择就是单纯的从提取到的所有特征中选择部分特征作为训练集特征，特征在选择前和选择后可以改变值、也可以不改变值，但是选择后的特征维数肯定比选择前小，因为只是选择了其中一部分特征。</p>
</blockquote>
<p>主要方法：</p>
<ul>
<li>Filter(过滤式):<ul>
<li>VarianceThreshold(方差过滤):由于方差为0的时候，一列的数据是一样的，所以是对结果没用的数据，由此推论，当方差小于某个值的时候，这个特征是不具有参考性的，可以剔除。<ul>
<li>sklearn.feature_selection.VarianceThreshold</li>
</ul>
</li>
</ul>
</li>
<li>Embedded(嵌入式):正则化、决策树</li>
<li>Wrapper(包裹式) </li>
<li>神经网络</li>
</ul>
<h4 id="主成分分析（PCA，principal-Component-Analysis）"><a href="#主成分分析（PCA，principal-Component-Analysis）" class="headerlink" title="主成分分析（PCA，principal Component Analysis）"></a>主成分分析（PCA，principal Component Analysis）</h4><p>背景：</p>
<blockquote>
<p>在许多领域的研究与应用中，通常需要对含有多个变量的数据进行观测，收集大量数据后进行分析寻找规律。多变量大数据集无疑会为研究和应用提供丰富的信息，但是也在一定程度上增加了数据采集的工作量。更重要的是在很多情形下，许多变量之间可能存在相关性，从而增加了问题分析的复杂性。如果分别对每个指标进行分析，分析往往是孤立的，不能完全利用数据中的信息，因此盲目减少特征会损失很多有用的信息，从而产生错误的结论。因此需要找到一种合理的方法，在减少需要分析的特征同时，尽量减少信息的损失，以达到对所收集数据进行全面分析的目的。由于各变量之间存在一定的相关关系，因此可以考虑将关系紧密的变量变成尽可能少的新变量，使这些新变量是两两不相关的，那么就可以用较少的综合指标分别代表存在于各个变量中的各类信息。主成分分析与因子分析就属于这类降维算法。<br>说白了就是特征太多情况下，如果很多特征之间是有联系的，这时直接通过特征选择等方式来剔除掉某些特征，会导致失去一些有用信息。所以需要一种方法，在减少特征数量的同时，尽可能少的减少信息的损失。</p>
</blockquote>
<p>PCA是什么？</p>
<blockquote>
<p>是一种使用最广泛的数据压缩算法。在PCA中，数据从原来的坐标系转换到新的坐标系，由数据本身决定。转换坐标系时，以方差最大的方向作为坐标轴方向，因为数据的最大方差给出了数据的最重要的信息。第一个新坐标轴选择的是原始数据中方差最大的方法，第二个新坐标轴选择的是与第一个新坐标轴正交且方差次大的方向。重复该过程，重复次数为原始数据的特征维数。<br>通过这种方式获得的新的坐标系，我们发现，大部分方差都包含在前面几个坐标轴中，后面的坐标轴所含的方差几乎为0,于是，我们可以忽略余下的坐标轴，只保留前面的方差较大的坐标轴。事实上，这样也就相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，也就实现了对数据特征的降维处理。<br>PCA里，特征数量会减少，但数据也会改变。一般特征数量达到上百才会用</p>
</blockquote>
<p>作用：</p>
<blockquote>
<p>可以削减回归分析或者聚类分析中特征的数量</p>
</blockquote>
<p>原理：<br>一张结果图：</p>
<img src="/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/%E9%99%8D%E7%BB%B4%E6%8A%95%E5%BD%B1.jpg" class="" title="降维投影">
<blockquote>
<p>详细过程参考这里的‘3.5PCA算法两种实现方法’：<a href="https://blog.csdn.net/program_developer/article/details/80632779" target="_blank" rel="noopener">https://blog.csdn.net/program_developer/article/details/80632779</a></p>
</blockquote>
<p>数据降维的两个方法demo：</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import VarianceThreshold</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">def var():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    特征选择-删除低方差的特征</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    var &#x3D; VarianceThreshold(threshold&#x3D;0.0)  # threshold指定方差阈值</span><br><span class="line">    data &#x3D; var.fit_transform([[0,2,0,3],[0,1,4,3],[0,1,1,3]])  #数据的第一列和最后一列方差为0</span><br><span class="line">    print(data)</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    过滤掉了第一列和最后一列</span><br><span class="line">    [[2 0]</span><br><span class="line">    [1 4]</span><br><span class="line">    [1 1]]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">def pca():</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    主成分分析进行特征降维</span><br><span class="line">    :return: None</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    pca &#x3D; PCA(n_components&#x3D;0.9)   # n_components可以选择保留的数据信息比例，一般为90%~95%</span><br><span class="line">    data &#x3D; pca.fit_transform([[2,4,6,8],[5,4,8,6],[1,5,6,3]])</span><br><span class="line">    print(data)</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    [[-1.32007718  2.16837282]</span><br><span class="line">    [-1.95237119 -1.90596201]</span><br><span class="line">    [ 3.27244837 -0.26241081]]</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    return None</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    pca()</span><br></pre></td></tr></table></figure>


<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><blockquote>
<p>算法是核心，数据和计算是基础。</p>
</blockquote>
<p>机器学习算法判别依据：数据类型</p>
<ul>
<li>离散型数据：由记录不同类别个体的数目所得到的数据，又称计数数据，所有这些数据全部都是整数，而且不能再细分，也不能进一步提高他们的精确度。<strong>区间内不可分</strong></li>
<li>连续型数据：变量可以在某个范围内取任一数，即变量的取值可以是连续的，如长度、时间、质量等，这类数值通常含有小数部分。<strong>区间内可分</strong></li>
</ul>
<p>机器学习算法分类：</p>
<ul>
<li>监督学习（预测）：有<strong>特征值和目标值</strong>，有标准答案<ul>
<li>分类：对应数据类型为<strong>离散型</strong><ul>
<li>k-近邻算法</li>
<li>贝叶斯分类</li>
<li>决策树与随机森林</li>
<li>逻辑回归</li>
<li>神经网络</li>
</ul>
</li>
<li>回归：对应数据类型为<strong>连续型</strong><ul>
<li>线性回归</li>
<li>岭回归</li>
</ul>
</li>
<li>标注<ul>
<li>隐马尔科夫模型</li>
</ul>
</li>
</ul>
</li>
<li>无监督学习：<strong>只有特征值</strong><ul>
<li>聚类<ul>
<li>k-means</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="机器学习开发流程"><a href="#机器学习开发流程" class="headerlink" title="机器学习开发流程"></a>机器学习开发流程</h3><ul>
<li>获取数据<blockquote>
<p>包括获取原始数据以及从原始数据中经过特征工程从原始数据中提取训练、测试数据</p>
</blockquote>
</li>
<li>特征工程<blockquote>
<p>包括从原始数据中特征构建、特征提取、特征选择。特征工程做的好能发挥原始数据的最大效力，往往能够使得算法的效果和性能得到显著的提升，有时能使简单的模型的效果比复杂的模型效果好。数据挖掘的大部分时间就花在特征工程上面，是机器学习非常基础而又必备的步骤。数据预处理、数据清洗、筛选显著特征、摒弃非显著特征等等都非常重要。</p>
</blockquote>
</li>
<li>训练模型、诊断、调优<blockquote>
<p>诊断中至关重要的是判断过拟合、欠拟合，常见的方法是绘制学习曲线，交叉验证。通过增加训练的数据量、降低模型复杂度来降低过拟合的风险，提高特征的数量和质量、增加模型复杂来防止欠拟合。诊断后的模型需要进行进一步调优，调优后的新模型需要重新诊断</p>
</blockquote>
</li>
<li>模型验证、误差分析<blockquote>
<p>主要是分析出误差来源与数据、特征、算法。</p>
</blockquote>
</li>
<li>模型融合<blockquote>
<p>提升算法的准确度主要方法是模型的前端（特征工程、清洗、预处理、采样）和后端的模型融合</p>
</blockquote>
</li>
<li>上线运行<blockquote>
<p>通过提供API等形式来上线</p>
</blockquote>
</li>
</ul>
<h1 id="sklearn数据集"><a href="#sklearn数据集" class="headerlink" title="sklearn数据集"></a>sklearn数据集</h1><h4 id="1-数据集划分"><a href="#1-数据集划分" class="headerlink" title="1.数据集划分"></a>1.数据集划分</h4><p>机器学习一般的数据集会划分为两个部分：</p>
<ul>
<li>训练数据：用户训练、构建模型</li>
<li>测试数据：在模型检验时使用，用于评估模型是否有效</li>
</ul>
<h4 id="2-sklearn数据集API介绍"><a href="#2-sklearn数据集API介绍" class="headerlink" title="2.sklearn数据集API介绍"></a>2.sklearn数据集API介绍</h4><ul>
<li>sklearn.model_selection.train_test_split</li>
<li>sklearn.datasets<ul>
<li>datasets.load_*();    获取小规模数据集，数据包含在datasets里</li>
<li>datasets.fetch_*(data_home=None);  获取大规模数据集，需要从网络上下载，第一个参数是data_home表示数据集下载的目录，默认 ‘~/scikit_learn_data/‘</li>
</ul>
<ul>
<li>load*和fetch*返回的数据类型都是datasets.base.Bunch(<strong>字典格式</strong>)<ul>
<li>data:特征数据数组，是[n_samples * m_features]的二维<strong>numpy.ndarry数组</strong></li>
<li>target:标签数组，是n_samples的<strong>一维numpy.ndarray数组</strong></li>
<li>DESCR:数据描述</li>
<li>feature_names:特征名，<strong>新闻数据、手写数字、回归数据集没有</strong></li>
<li>target_names:标签名</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="3-sklearn分类数据集，对应分类算法"><a href="#3-sklearn分类数据集，对应分类算法" class="headerlink" title="3.sklearn分类数据集，对应分类算法"></a>3.sklearn分类数据集，对应分类算法</h4><blockquote>
<p>此处以内置数据集 load_iris和20newsgroups 为例</p>
</blockquote>
<p>1.load_iris()获取内置普通分类用的数据集<br>2.获取用于分类测试的大数据集，sklearn.datasets.fetch_20newgroups(),数据集收集了大约20,000左右的新闻组文档，均匀分为20个不同主题的新闻组集合。</p>
<blockquote>
<p>datasets.clear</p>
</blockquote>
<p>数据集进行分割：<br>sklearn.model_selection.train_test_split(<em>arrays,*</em>options)</p>
<ul>
<li>x:数据集的特征值</li>
<li>y:数据集的标签值</li>
<li>test_size:测试集大小，一般为float</li>
<li>random_state:随机数种子</li>
<li>return:训练集特征值，测试集特征值，训练标签，测试标签</li>
</ul>
<p>下面为两个数据集的获取代码，目前仅为数据采集，至于特征提取、模型训练等后续再写</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from sklearn.datasets import load_iris, fetch_20newsgroups</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">内置的数据集，加载并返回鸢尾花数据集</span><br><span class="line">类别：3</span><br><span class="line">特征：4</span><br><span class="line">样本数量：150</span><br><span class="line">每个类别数量：50</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">li &#x3D; load_iris()</span><br><span class="line"></span><br><span class="line">print(li.data)  # 获取特征数据数组</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">[[5.1 3.5 1.4 0.2]</span><br><span class="line"> [4.9 3.  1.4 0.2]</span><br><span class="line"> [4.7 3.2 1.3 0.2]</span><br><span class="line"> ......</span><br><span class="line"> [5.9 3.  5.1 1.8]]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">print(li.target)  # 获取目标值</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">目标值是离散型，0，1，2</span><br><span class="line">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span><br><span class="line"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span><br><span class="line"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span><br><span class="line"> 2 2]</span><br><span class="line">.. _iris_dataset:</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">    # print(li.DESCR)     #打印出一些描述信息</span><br><span class="line"></span><br><span class="line">train_feature, test_feature, train_target, test_target &#x3D; train_test_split(li.data, li.target,</span><br><span class="line">                                                                          test_size&#x3D;0.25)  # 参数：特征值，目标值，测试集大小</span><br><span class="line">    # 返回值依次为：训练集的特征值、测试集特征值、训练集目标值、测试集目标值</span><br><span class="line"></span><br><span class="line">print(&quot;训练集特征值和目标值：&quot;, train_feature, train_target)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">训练集特征值和目标值： [[6.4 3.2 5.3 2.3]</span><br><span class="line"> [4.6 3.6 1.  0.2]</span><br><span class="line"> [5.5 2.5 4.  1.3]</span><br><span class="line"> ......</span><br><span class="line"> [5.7 2.8 4.1 1.3]</span><br><span class="line"> [5.5 2.4 3.7 1. ]]</span><br><span class="line"> [2 0 1 1 2 2 0 1 1 0 2 2 2 0 1 1 2 2 1 1 1 0 0 2 1 2 1 0 1 1 0 0 1 0 0 0 2</span><br><span class="line"> 2 0 0 1 1 1 1 1 0 1 2 0 0 0 2 1 0 0 1 1 0 1 1 1 0 0 2 0 1 2 2 2 0 2 0 2 2</span><br><span class="line"> 0 1 2 0 1 0 2 2 2 0 2 0 1 0 1 0 1 0 2 1 1 1 0 1 1 1 2 2 2 0 0 2 2 2 0 2 1</span><br><span class="line"> 1]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">print(&quot;测试集特征值和目标值：&quot;, test_feature, test_target)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">测试集特征值和目标值： [[6.3 2.9 5.6 1.8]</span><br><span class="line"> [6.3 2.5 4.9 1.5]</span><br><span class="line"> [7.3 2.9 6.3 1.8]</span><br><span class="line"> ......</span><br><span class="line"> [4.4 2.9 1.4 0.2]</span><br><span class="line"> [5.1 3.4 1.5 0.2]]</span><br><span class="line"> [2 1 2 2 2 1 2 0 2 2 2 0 0 2 0 0 1 1 1 1 2 2 0 2 2 1 1 2 2 0 0 1 1 0 0 2 0 0]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">也是一个内置的数据集，不过是是大数据集，会从网络下载</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">news &#x3D; fetch_20newsgroups(data_home&#x3D;r&quot;G:\pyMechineLearn&quot;, subset&#x3D;&#39;all&#39;)</span><br><span class="line">print(news.data)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">貌似是一个list类型，每一个元素是str类型，也就是一篇文章。</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">print(news.target)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">不同的数对应不同的文章类型</span><br><span class="line">[10  3 17 ...  3  1  7]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-sklearn回归数据集，对应回归算法"><a href="#4-sklearn回归数据集，对应回归算法" class="headerlink" title="4.sklearn回归数据集，对应回归算法"></a>4.sklearn回归数据集，对应回归算法</h4><blockquote>
<p>此处以内置数据集 波士顿房价数据集为例<br>sklearn.datasets.load_boston()</p>
</blockquote>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from sklearn.datasets import load_boston</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">波士顿房价数据</span><br><span class="line">目标类别：5-50</span><br><span class="line">特征：13</span><br><span class="line">样本数量：506</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">lb &#x3D; load_boston()</span><br><span class="line"></span><br><span class="line">print(lb.data)  #获取特征值</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">特征值就是收集的属性，房子的一些大小等信息</span><br><span class="line">[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]</span><br><span class="line"> [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]</span><br><span class="line"> [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]</span><br><span class="line"> ...</span><br><span class="line"> [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]</span><br><span class="line"> [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]</span><br><span class="line"> [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">print(lb.target)    #获取目标值</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4</span><br><span class="line"> 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8</span><br><span class="line">.......</span><br><span class="line">  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9</span><br><span class="line"> 22.  11.9]</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">print(lb.DESCR) #描述信息</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">\*\*Data Set Characteristics:\*\* </span><br><span class="line">:Number of Instances: 506</span><br><span class="line">:Attribute Information (in order):</span><br><span class="line">        - CRIM     per capita crime rate by town</span><br><span class="line">        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.</span><br><span class="line">        - INDUS    proportion of non-retail business acres per town</span><br><span class="line">        .........</span><br><span class="line">        - MEDV     Median value of owner-occupied homes in $1000&#39;s</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>

<h1 id="转换器（Transformer）与估计器（estimator）"><a href="#转换器（Transformer）与估计器（estimator）" class="headerlink" title="转换器（Transformer）与估计器（estimator）"></a>转换器（Transformer）与估计器（estimator）</h1><p>特征工程中，实例化出来的可调用fit_transform API的对象（如 DictVectorizer等）就是一个Transformer</p>
<ul>
<li>fit_transform():输入数据直接转换</li>
<li>fit()+transform():fit是单纯的输入数据，然后进行一些预先处理，如计算平均值，方差等。transform是进行数据的转换</li>
</ul>
<p>在sklearn中，估计器（estimator）是一个重要的角色，是一类实现了算法的API，这玩意不是知道接口是啥就可以，而是传入的算法参数- -。。</p>
<ul>
<li>用于分类的估计器：<ul>
<li>sklearn.neighbors k-近邻算法</li>
<li>sklearn.naive_bayes 贝叶斯</li>
<li>sklearn.linear_model.logisticRegression 逻辑回归</li>
<li>sklearn.tree 决策树与随机森林</li>
</ul>
</li>
<li>用于分类的估计器：<ul>
<li>sklearn.linear_model.linearRegression 线性回归</li>
<li>sklearn.linear_model.Ridge 岭回归</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/11/python%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%80/" data-id="ckccph4ii0008y81r1wo55rfu" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-python数据分析基础" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/11/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/" class="article-date">
  <time class="post-time" datetime="2020-01-11T09:25:24.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/11/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/">python数据分析基础</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li>Python VS R 语言(原文：<a href="https://mp.weixin.qq.com/s/CAsVeEJlgru85NUHcUKv6A)：" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/CAsVeEJlgru85NUHcUKv6A)：</a><blockquote>
<ul>
<li>什么是R语言？<br>R语言，一种自由软件编程语言与操作环境，主要用于统计分析、绘图、数据挖掘。R基于S语言的一个GNU计划项目，所以也可以当作S语言的一种实现。</li>
<li>Python与R语言共同特点</li>
<li>Python和R在数据分析和数据挖掘方面都有比较专业和全面的模块，很多常用的功能，比如矩阵运算、向量运算等都有比较高级的用法</li>
<li>Python和R两门语言有多平台适应性，linux、window都可以使用，并且代码可移植性强</li>
<li>Python和R比较贴近MATLAB以及minitab等常用的数学工具</li>
<li>Python与R语言区别</li>
<li>数据结构方面，由于是从科学计算的角度出发，R中的数据结构非常的简单，主要包括向量(一维)、多维数组(二维时为矩阵)、列表(非结构化数据)、数据框(结构化数据)。而 Python 则包含更丰富的数据结构来实现数据更精准的访问和内存控制，多维数组(可读写、有序)、元组(只读、有序)、集合(唯一、无序)、字典(Key-Value)等等。</li>
<li>Python与R相比速度要快。Python可以直接处理上G的数据;R不行，R分析数据时需要先通过数据库把大数据转化为小数据(通过groupby)才能交给R做分析，因此R不可能直接分析行为详单，只能分析统计结果。</li>
<li>Python是一套比较平衡的语言，各方面都可以，无论是对其他语言的调用，和数据源的连接、读取，对系统的操作，还是正则表达和文字处理，Python都有着明显优势。 而R是在统计方面比较突出。</li>
<li>总结<br>总的来说，Python 的 pandas 借鉴了R的dataframes，R 中的 rvest 则参考了 Python的BeautifulSoup，两种语言在一定程度上存在互补性，通常，我们认为 Python 比 R 在计算机编程、网络爬虫上更有优势，而 R 在统计分析上是一种更高效的独立数据分析工具。所以说，同时学会Python和R这两把刷子才是数据科学的王道。</li>
</ul>
</blockquote>
</li>
</ul>
<p>python其实是可以直接<strong>调用R语言的函数</strong>的，只需要安装rpy2模块即可。</p>
<h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><p>提到数据分析，就不得不考虑到数据分析后的展示，Matplotlib是一个Python 2D绘图库，它可以在各种平台上以各种硬拷贝格式和交互式环境生成出具有出版品质的图形。<br>至于matplotlib的安装，可以通过 Anaconda来安装，相关操作不多赘述。</p>
<h4 id="折线图示例"><a href="#折线图示例" class="headerlink" title="折线图示例"></a>折线图示例</h4><img src="/2020/01/11/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/%E6%8A%98%E7%BA%BF%E5%9B%BE.jpg" class="" title="折线图">
<p>相关api在代码中都有注释<br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="comment"># 折线图</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：matplotlib默认时不支持中文的，可通过rc修改</span></span><br><span class="line">font = &#123;<span class="string">'family'</span>: <span class="string">'SimHei'</span>,</span><br><span class="line">        <span class="string">'weight'</span>: <span class="string">'bold'</span>,</span><br><span class="line">        <span class="string">'size'</span>: <span class="string">'16'</span>&#125;</span><br><span class="line">matplotlib.rc(<span class="string">'font'</span>, **font)</span><br><span class="line"></span><br><span class="line">x = range(<span class="number">2</span>, <span class="number">26</span>, <span class="number">2</span>)</span><br><span class="line">y = [<span class="number">15</span>, <span class="number">13</span>, <span class="number">12</span>, <span class="number">11</span>, <span class="number">15</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">14.5</span>, <span class="number">6.3</span>, <span class="number">21.2</span>, <span class="number">10</span>]</span><br><span class="line"><span class="comment"># 要在一个图形上绘制多个曲线，可直接设置另一个列表然后通过plot来绘制</span></span><br><span class="line">another_y = [<span class="number">10</span>, <span class="number">10</span>, <span class="number">22</span>, <span class="number">15</span>, <span class="number">13</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">11.5</span>, <span class="number">20</span>, <span class="number">21.2</span>, <span class="number">20</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图片大小</span></span><br><span class="line"><span class="comment"># plt.figure(figsize=(20, 8), dpi=80)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图，label为折线名字，需要在后面添加legend方法才能显示在图形上，还可设置线条颜色和style等</span></span><br><span class="line">plt.plot(x, y, label=<span class="string">"第一条"</span>)</span><br><span class="line"><span class="comment"># 绘制另一条曲线</span></span><br><span class="line">plt.plot(x, another_y, label=<span class="string">"第二条"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制x轴的刻度,根据列表参数的值展示刻度</span></span><br><span class="line"><span class="comment"># plt.xticks(x)</span></span><br><span class="line"><span class="comment"># plt.xticks(range(2,25))</span></span><br><span class="line"><span class="comment"># x轴刻度显示字符串, 需要构造一个和xticks第一个参数一一对应的字符串列表，这也可以解决xy轴刻度对不准问题，自定义在哪里显示刻度和显示什么</span></span><br><span class="line">_xstring_labels = [<span class="string">"string&#123;&#125;"</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">plt.xticks(x, _xstring_labels, rotation=<span class="number">90</span>)  <span class="comment"># rotation可以让x刻度旋转一定角度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示y轴刻度</span></span><br><span class="line">plt.yticks(range(min(y), max(y)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图形和坐标轴的描述信息</span></span><br><span class="line">plt.xlabel(<span class="string">"x轴信息"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y轴信息"</span>)</span><br><span class="line">plt.title(<span class="string">"图形名字"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制网格,参数alpha可以设置透明度</span></span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例，loc参数可设置图例位置</span></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示图形</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存图形,后缀为svg可以保存为矢量图</span></span><br><span class="line"><span class="comment"># plt.savefig("./testone.png")</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="其他图形示例"><a href="#其他图形示例" class="headerlink" title="其他图形示例"></a>其他图形示例</h4><p>绘制其他图形的api和折线图几乎相同，程序参考上面就可以，下面列举一下api以供参考<br>其中 x,y为x和y轴的列表</p>
<ul>
<li>散点图<ul>
<li>plt.scatter(x,y)</li>
</ul>
</li>
<li>条形图<ul>
<li>plt.bar(x,y,width=’0.3’) #width为设置线条的粗细</li>
<li>plt.hbar(x,y,height=’0.3’)   #绘制横向的条形图,height为横向线条的粗细</li>
<li>通过设置 xticks可以实现数字和字符串的相对应</li>
</ul>
</li>
<li>直方图<ul>
<li>plt.hist(a,num_bins,normed = True)  #a为数据列表，num_bins为数据分为多少组，normed用来设置是否是频率直方图。<ul>
<li>组数 = 极差/组距 = (max(a) - min(a))/自己设置的组距，注：最大值-最小值的结果一定要能被组距整除，不然图像会出现偏差</li>
</ul>
</li>
<li>当组距不均匀时，plt.hist(a,[min(a)+i*组距 for i in range(组数)])，也就是可以传入一个列表，长度为组数，值为分组的依据</li>
<li>小技巧，设置x轴刻度：plt.xticks(range(min(a),man(a)+d,d)) ,因为range是去[),所以最后不加d的话会导致最后一个刻度丢失</li>
</ul>
</li>
<li>more<ul>
<li>matplotlib官网中有很多例子，网址：<a href="https://matplotlib.org/gallery/index.html" target="_blank" rel="noopener">https://matplotlib.org/gallery/index.html</a> ，需要的时候可根据问题自行查找。</li>
</ul>
</li>
</ul>
<h2 id="其他的一些绘制工具"><a href="#其他的一些绘制工具" class="headerlink" title="其他的一些绘制工具"></a>其他的一些绘制工具</h2><ul>
<li>百度的一个前端框架echarts：<a href="https://www.echartsjs.com/index.html" target="_blank" rel="noopener">https://www.echartsjs.com/index.html</a> ，讲道理确实很炫酷。可动态交互</li>
<li>python的图形库plotly：<a href="https://plot.ly/python/" target="_blank" rel="noopener">https://plot.ly/python/</a> ， 可以在线生成交互式、高质量的图形。可动态交互</li>
<li>Seaborn，基于matplotlib的Python数据可视化库：<a href="http://seaborn.pydata.org/" target="_blank" rel="noopener">http://seaborn.pydata.org/</a> 。 静态</li>
</ul>
<h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>什么是Numpy</p>
<blockquote>
<p>NumPy系统是Python的一种开源的数值计算扩展，是python科学计算的基础包。这种工具可用来存储和处理大型矩阵，具有快速高效的多维数组对象ndarray，比Python自身的嵌套列表（nested list structure)结构要高效的多。NumPy（Numeric Python）提供了许多高级的数值编程工具，如：矩阵数据类型、矢量处理，以及精密的运算库。专为进行严格的数字处理而产生。可以用来处理线性代数运算、傅里叶变换以及随机数生成等。</p>
</blockquote>
<p>下面列出了一些列numpy常用的API可供参考：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy 创建数组</span></span><br><span class="line">t1 = numpy.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])  <span class="comment"># [1,2,3]</span></span><br><span class="line">t2 = numpy.array(range(<span class="number">1</span>, <span class="number">6</span>))  <span class="comment"># [1,2,3,4,5]</span></span><br><span class="line">t3 = numpy.arange(<span class="number">4</span>, <span class="number">10</span>, <span class="number">2</span>)  <span class="comment"># [4,6,8]</span></span><br><span class="line"></span><br><span class="line">print(t3.dtype)  <span class="comment"># int32 与平台有关，还可能是int64,float32等</span></span><br><span class="line">t4 = numpy.arange(<span class="number">4</span>, <span class="number">10</span>, <span class="number">2</span>, dtype=<span class="string">"int64"</span>)  <span class="comment"># 可以手动指定数值类型</span></span><br><span class="line"><span class="comment"># 调整数据类型</span></span><br><span class="line">t5 = t4.astype(<span class="string">"float32"</span>)</span><br><span class="line">print(t5.dtype)</span><br><span class="line"></span><br><span class="line">t6 = random.random()</span><br><span class="line">t6 = numpy.round(t6, <span class="number">2</span>)  <span class="comment"># round保留两位小数</span></span><br><span class="line">print(t6)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">numpy读取本地CSV文件</span></span><br><span class="line"><span class="string">api：numpy.loadtxt(fname, dtype=, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0)</span></span><br><span class="line"><span class="string">fname :文件或字符串</span></span><br><span class="line"><span class="string">dtype : 数据类型</span></span><br><span class="line"><span class="string">comments :用于指示注释开头的字符，默认值为 : '#'.</span></span><br><span class="line"><span class="string">delimiter :用于分隔值的字符，缺省值为任何空白字符，如空格 ，制表符  </span></span><br><span class="line"><span class="string">converters : dict字典 ，用来定义将对应的列转换为浮点数的函数。列入：0列是日期字符串："converters=&#123;0:datestr2num&#125;".convertes 同时也能够为丢失的数据设置缺省值："convertes=&#123;3:lambda s:float(s.strip() or 0)&#125;"</span></span><br><span class="line"><span class="string">skiprows:跳过开头的行数</span></span><br><span class="line"><span class="string">usecols : 确定那几列被读取</span></span><br><span class="line"><span class="string">unpack :是否进行转置</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># n1 = numpy.loadtxt("test.csv",delimiter=",",dtype="int") # t1= [ [0行0列 0行1列 0行2列] [1行0列 1行1列 1行2列] [2行0列 2行1列 2行2列] ]</span></span><br><span class="line"></span><br><span class="line">n2 = numpy.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">    [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 索引和切片</span></span><br><span class="line"><span class="comment"># print(n2[行,列]) ‘：’表所有</span></span><br><span class="line"><span class="comment"># 取一行</span></span><br><span class="line">print(n2[<span class="number">1</span>])  <span class="comment"># [5 6 7 8]</span></span><br><span class="line"><span class="comment"># 取连续多行</span></span><br><span class="line">print(n2[<span class="number">1</span>:])  <span class="comment"># [[5 6 7 8] [9 10 11 12]]</span></span><br><span class="line"><span class="comment"># 取不连续多行</span></span><br><span class="line">print(n2[[<span class="number">0</span>, <span class="number">2</span>]])  <span class="comment"># [ [1 2 3 4] [9 10 11 12]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取列</span></span><br><span class="line">print(n2[:, <span class="number">0</span>])  <span class="comment"># [1 5 9]</span></span><br><span class="line"><span class="comment"># 连续多列</span></span><br><span class="line">print(n2[:, <span class="number">2</span>:])  <span class="comment"># [ [3 4] [7 8 ] [11 12]]</span></span><br><span class="line"><span class="comment"># 不连续的列</span></span><br><span class="line">print(n2[:, [<span class="number">0</span>, <span class="number">2</span>]])  <span class="comment"># [ [1 3][5 7][9 11] ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取单行单列和多行多列</span></span><br><span class="line">print(n2[[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>]])  <span class="comment"># 注意，这里是 [2 7]</span></span><br><span class="line">print(n2[<span class="number">1</span>, <span class="number">2</span>])  <span class="comment"># [7]</span></span><br><span class="line">print(n2[<span class="number">0</span>:<span class="number">2</span>, <span class="number">0</span>:<span class="number">3</span>])  <span class="comment"># [[1 2 3][5 6 7]] ，这里的多行多列，‘:’的区间是[)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据拼接</span></span><br><span class="line">n3 = numpy.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">])</span><br><span class="line">n4 = numpy.array([</span><br><span class="line">    [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">    [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 横向和竖向拼接</span></span><br><span class="line">numpy.vstack((n3, n4))  <span class="comment"># [[1 2 3 4] [5 6 7 8] [9 10 11 12] [...]]</span></span><br><span class="line">numpy.hstack((n3, n4))  <span class="comment"># [ [1 2 3 4 9 10 11 12] [5 6 7 8 11 12 13 14]]</span></span><br><span class="line"><span class="comment"># numpy数组可以支持 a b = b a语法来换行或者换列，如</span></span><br><span class="line">n2[[<span class="number">1</span>, <span class="number">2</span>], :] = n2[[<span class="number">2</span>, <span class="number">1</span>], :]  <span class="comment"># 行交换</span></span><br><span class="line">n2[:, [<span class="number">0</span>, <span class="number">1</span>]] = n2[:, [<span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># 列交换</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h2><p>为什么需要pandas？</p>
<blockquote>
<p>numpy能够帮我们处理数值型数据，但这样还不足以满足需求，有时候还需要处理字符串、时间序列等。不过pandas的数值处理模块也是基于numpy的。</p>
</blockquote>
<p>什么是pandas？</p>
<blockquote>
<p>pandas 是是python的一个数据分析包、基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。对于金融行业的用户，pandas提供了大量适用于金融数据的高性能时间序列功能和工具。</p>
</blockquote>
<p>pandas的数据结构：</p>
<ul>
<li>Series：带标签(索引)的一维数组，与Numpy中的一维array类似。二者与Python基本的数据结构List也很相近，其区别是：List中的元素可以是不同的数据类型，而Array和Series中则只允许存储相同的数据类型，这样可以更有效的使用内存，提高运算效率。</li>
<li>Time- Series：以时间为索引的Series。</li>
<li>DataFrame：二维的表格型数据结构。很多功能与R中的data.frame类似。可以将DataFrame理解为Series的容器。</li>
<li>Panel ：三维的数组，可以理解为DataFrame的容器。</li>
</ul>
<p>pandas的相关用法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding = 'utf-8'</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Series相关</span></span><br><span class="line"></span><br><span class="line">t1 = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">5</span>])</span><br><span class="line">t2 = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], index=list(<span class="string">"abcde"</span>))  <span class="comment"># 此时 1的索引为a,2的索引为b,以此类推</span></span><br><span class="line">print(t2.dtype)  <span class="comment"># int64</span></span><br><span class="line">temp_list = &#123;<span class="string">"name"</span>: <span class="string">"q"</span>, <span class="string">"age"</span>: <span class="number">26</span>, <span class="string">"tel"</span>: <span class="string">"10086"</span>&#125;</span><br><span class="line">t3 = pd.Series(temp_list)  <span class="comment"># 此时索引为字典的键，值为字典对应键的值</span></span><br><span class="line"><span class="comment"># tip:对一个series重新指定索引后，如果能够对应上，就取其值，如果不能，则为Nan</span></span><br><span class="line">print(t3.dtype)  <span class="comment"># object</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Series的切片和索引</span></span><br><span class="line">print(t3[:<span class="number">2</span>])  <span class="comment"># 取前3行</span></span><br><span class="line">print(t3[[<span class="string">"name"</span>, <span class="string">"age"</span>]])  <span class="comment"># 取name和age</span></span><br><span class="line">print(t1[t1 &gt; <span class="number">2</span>])  <span class="comment"># 取值大于2的</span></span><br><span class="line">print(t3.index)  <span class="comment"># 获取索引列表，类型为Index，可以使用list(t3.index) 强制转换为列表</span></span><br><span class="line">print(t3.values)  <span class="comment"># 获取值的列表,类型为numpy.ndarry，其实就是一个数组</span></span><br><span class="line"><span class="comment"># tips：ndarry中很多方法在pandas中都可以用。但pandas中的where是不同的,可以用来查找符合条件的数值，而不符合的显示为指定的值，不指定则为Nan</span></span><br><span class="line">print(<span class="string">'*'</span> * <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataFrame相关</span></span><br><span class="line"></span><br><span class="line">p1 = pd.DataFrame(np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">print(p1)</span><br><span class="line"><span class="comment"># 带索引的创建,指定行索引和列索引</span></span><br><span class="line">p2 = pd.DataFrame(np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>), index=list(<span class="string">"abc"</span>), columns=list(<span class="string">"WXYZ"</span>))</span><br><span class="line">print(p2)</span><br><span class="line"><span class="comment"># 传入字典创建,键为列名,每一行为具体的值，值可以对应一个列表，列表内有多少数据就有多少行。也可以传入一个内容是字典的列表，有几个字典就有几行。没有的数据为NaN</span></span><br><span class="line">d1 = &#123;<span class="string">"name"</span>: [<span class="string">"q1"</span>, <span class="string">"q2"</span>], <span class="string">"age"</span>: [<span class="number">25</span>, <span class="number">26</span>], <span class="string">"tel"</span>: [<span class="number">10086</span>, <span class="number">10010</span>]&#125;</span><br><span class="line">p3 = pd.DataFrame(d1)</span><br><span class="line">print(p3)</span><br><span class="line">d2 = [&#123;<span class="string">"name"</span>: <span class="string">"q1"</span>, <span class="string">"age"</span>: <span class="number">25</span>, <span class="string">"tel"</span>: <span class="number">10010</span>&#125;, &#123;<span class="string">"name"</span>: <span class="string">"q2"</span>, <span class="string">"tel"</span>: <span class="number">10000</span>&#125;, &#123;<span class="string">"name"</span>: <span class="string">"q3"</span>, <span class="string">"age"</span>: <span class="number">22</span>, <span class="string">"tel"</span>: <span class="number">10086</span>&#125;]</span><br><span class="line">p4 = pd.DataFrame(d2)</span><br><span class="line">print(p4)</span><br><span class="line"><span class="comment"># 前几行，tail为尾几行。info可以查看DataFrame的内存情况，多少行多少列占用多少内存等</span></span><br><span class="line">p4.head(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataFrame取行取列，方括号内写数组，表示取行，写字符串，表示取列的索引</span></span><br><span class="line">p5 = pd.DataFrame(np.arange(<span class="number">100</span>).reshape(<span class="number">10</span>, <span class="number">10</span>), index=[<span class="string">"r1"</span>, <span class="string">"r2"</span>, <span class="string">"r3"</span>, <span class="string">"r4"</span>, <span class="string">"r5"</span>, <span class="string">"r6"</span>, <span class="string">"r7"</span>, <span class="string">"r8"</span>, <span class="string">"r9"</span>, <span class="string">"r10"</span>],</span><br><span class="line">                  columns=[<span class="string">"c1"</span>, <span class="string">"c2"</span>, <span class="string">"c3"</span>, <span class="string">"c4"</span>, <span class="string">"c5"</span>, <span class="string">"c6"</span>, <span class="string">"c7"</span>, <span class="string">"c8"</span>, <span class="string">"c9"</span>, <span class="string">"c10"</span>])</span><br><span class="line"><span class="comment"># 取前5行</span></span><br><span class="line">print(p5[:<span class="number">5</span>])</span><br><span class="line"><span class="comment"># 取固定列</span></span><br><span class="line">print(p5[<span class="string">"c2"</span>])</span><br><span class="line"><span class="comment"># 通过pandas优化过的选择方式：</span></span><br><span class="line"><span class="comment"># loc通过标签索引行数据，loc中冒号两边的数据取的方式是闭合区间[]，而不是[)</span></span><br><span class="line"><span class="comment"># iloc通过位置获取行数据</span></span><br><span class="line">print(p5.loc[<span class="string">"r4"</span>, <span class="string">"c5"</span>])  <span class="comment"># 取r4行r5列</span></span><br><span class="line">print(p5.loc[<span class="string">"r4"</span>])  <span class="comment"># 取r4行</span></span><br><span class="line">print(p5.loc[[<span class="string">"r1"</span>, <span class="string">"r3"</span>]])  <span class="comment"># 取多行多列语法 如r1行和r3行</span></span><br><span class="line">print(p5.iloc[:, <span class="number">2</span>])  <span class="comment"># 取第2列,索引从0开始</span></span><br><span class="line">print(p5.iloc[<span class="number">5</span>:, <span class="number">3</span>:])  <span class="comment">#取第6行以后和第3列以后的数据</span></span><br><span class="line">print(p5[p5[<span class="string">"c7"</span>]&gt;<span class="number">70</span>])  <span class="comment">#取c7列大于70的所有行</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#缺失数据NaN的处理</span></span><br><span class="line">p6 = pd.DataFrame(np.array([<span class="number">0</span>,<span class="number">1</span>,np.NaN,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,np.NaN,<span class="number">10</span>,<span class="number">11</span>]).reshape(<span class="number">3</span>, <span class="number">4</span>), index=list(<span class="string">"abc"</span>), columns=list(<span class="string">"WXYZ"</span>))</span><br><span class="line">print(p6)</span><br><span class="line">print(pd.notnull(p6))   <span class="comment">#p6中，不为NaN的值显示为true，为NaN的值显示为false</span></span><br><span class="line">print(p6[pd.notnull(p6[<span class="string">"X"</span>])])  <span class="comment">#选取p6的X列中的值不为NaN的所有行</span></span><br><span class="line">print(p6.dropna(axis=<span class="number">0</span>,how=<span class="string">"any"</span>))    <span class="comment">#删除DataFrame中值为NaN的axis，axis=0为行，1为列。how的值为“any”表示这个轴只要有NaN就删，值为“all”表示所有值都为NaN才删</span></span><br><span class="line"><span class="comment">#填充NaN为指定数据</span></span><br><span class="line">print(p6.fillna(<span class="number">0</span>))     <span class="comment"># 将NaN填充为0</span></span><br><span class="line"><span class="comment"># 不过为了数据完整性，一般不会填充为0或者随便填一个数值，而是会填充为均值,Pandas计算均值的时候不会算上NaN值</span></span><br><span class="line">print(p6.mean())    <span class="comment">#此时mean算的均值是每一列的均值</span></span><br><span class="line">print(p6.fillna(p6.mean()))</span><br><span class="line">print(p6[<span class="string">"X"</span>].fillna(p6[<span class="string">"X"</span>].mean()))   <span class="comment">#只填充某一列的NaN值，如果要改变原数据,可以前面添加 p6["X"] =</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas读取外部数据</span></span><br><span class="line"><span class="comment"># csv文件</span></span><br><span class="line"><span class="comment"># result = pd.read_csv("./test.csv")</span></span><br><span class="line"><span class="comment"># 读取sql，传入sql语句和connection</span></span><br><span class="line"><span class="comment"># pd.read_sql(sql_sentence,connection)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="写到这里"><a href="#写到这里" class="headerlink" title="写到这里"></a>写到这里</h1><p>先上一张python数据分析的知识框架</p>
<img src="/2020/01/11/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.jpg" class="" title="数据库结果">
<p>其中有一些还没有写到，也不打算继续挖坑了，暂且记录在下面：</p>
<ul>
<li>Scipy<ul>
<li>Scipy是一组专门解决科学计算中各种标准问题域的包的集合。</li>
</ul>
</li>
<li>statsmodels<ul>
<li><a href="https://github.com/statsmodels/statsmodels" target="_blank" rel="noopener">https://github.com/statsmodels/statsmodels</a></li>
</ul>
</li>
<li>scikit-learn<ul>
<li><a href="http://scikit-learn.org/stable/" target="_blank" rel="noopener">http://scikit-learn.org/stable/</a></li>
</ul>
</li>
</ul>
<p>这段时间大概了解了一下python数据分析的知识框架，写的不是很详细，这里有一篇更详细的文章写得不错先mark一下：<a href="https://www.cnblogs.com/nxld/p/6058998.html" target="_blank" rel="noopener">https://www.cnblogs.com/nxld/p/6058998.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/11/python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%9F%BA%E7%A1%80/" data-id="ckccph4iq000oy81rdm260l29" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-scrapy爬取腾讯招聘岗位到mongoDB中" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/11/scrapy%E7%88%AC%E5%8F%96%E8%85%BE%E8%AE%AF%E6%8B%9B%E8%81%98%E5%B2%97%E4%BD%8D%E5%88%B0mongoDB%E4%B8%AD/" class="article-date">
  <time class="post-time" datetime="2020-01-11T05:42:20.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/11/scrapy%E7%88%AC%E5%8F%96%E8%85%BE%E8%AE%AF%E6%8B%9B%E8%81%98%E5%B2%97%E4%BD%8D%E5%88%B0mongoDB%E4%B8%AD/">scrapy爬取腾讯招聘岗位到mongoDB中</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近正值一年一度的春招时刻，看到一堆学弟学妹忙着准备简历和面试，默默地打开了腾讯的招聘网站，<a href="https://hr.tencent.com/position.php" target="_blank" rel="noopener">https://hr.tencent.com/position.php</a> ，打算爬取一下所有的岗位信息，工作地点，类型，以及日期。</p>
<p>借此来复习一下Scrapy这个框架的基本使用，爬取的数据则是存储在本地的MongoDB数据库中。<br>Scrapy的架构图如下：</p>
<img src="/2020/01/11/scrapy%E7%88%AC%E5%8F%96%E8%85%BE%E8%AE%AF%E6%8B%9B%E8%81%98%E5%B2%97%E4%BD%8D%E5%88%B0mongoDB%E4%B8%AD/Scrapy.jpg" class="" title="Scrapy架构">

<p>Scrapy主要包括了以下组件：</p>
<ul>
<li>引擎(Scrapy)<ul>
<li>用来处理整个系统的数据流, 触发事务(框架核心)</li>
</ul>
</li>
<li>调度器(Scheduler)<ul>
<li>用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</li>
</ul>
</li>
<li>下载器(Downloader)<ul>
<li>用于下载网页内容, 并将网页内容返回给spider(Scrapy下载器是建立在twisted这个高效的异步模型上的)</li>
</ul>
</li>
<li>爬虫(Spiders)<ul>
<li>爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面</li>
</ul>
</li>
<li>项目管道(Pipeline)<ul>
<li>负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。</li>
</ul>
</li>
<li>下载器中间件(Downloader Middlewares)<ul>
<li>位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。</li>
</ul>
</li>
<li>爬虫中间件(Spider Middlewares)<ul>
<li>介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。</li>
</ul>
</li>
<li>调度中间件(Scheduler Middewares)<ul>
<li>介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。</li>
</ul>
</li>
</ul>
<p>Scrapy运行流程大概如下：</p>
<ul>
<li>引擎从调度器中取出一个链接(URL)用于接下来的抓取</li>
<li>引擎把URL封装成一个请求(Request)传给下载器</li>
<li>下载器把资源下载下来，并封装成应答包(Response)</li>
<li>爬虫解析Response</li>
<li>解析出实体（Item）,则交给实体管道进行进一步的处理</li>
<li>解析出的是链接（URL）,则把URL交给调度器等待抓取</li>
</ul>
<h2 id="建立项目"><a href="#建立项目" class="headerlink" title="建立项目"></a>建立项目</h2><p>假设已经安装好mongodb数据库和scrapy。<br>windows下，cd到对应的文件夹目录</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject myspiders</span><br><span class="line">#cd到 myspiders 文件夹下</span><br><span class="line">scrapy genspider myspider tencent.com</span><br></pre></td></tr></table></figure>

<p>这之后在项目的spiders文件夹下，会生成一个 myspider.py 的文件，修改里面的 start_urls为我们的起始地址 <a href="https://hr.tencent.com/position.php" target="_blank" rel="noopener">https://hr.tencent.com/position.php</a><br>settings.py文件中，去掉 ITEM_PIPELINES 的注释，以使pipelines.py文件可以使用<br>settings.py中添加一行log等级，过滤一下多余log，LOG_LEVEL = “WARNING”<br>settings.py中的USER_AGENT取消注释，并改为自己浏览器的useragent</p>
<blockquote>
<p>Request参数参考：scrapy.http.Request(url[, callback, method=’GET’, headers, body, cookies, meta, encoding=’utf-8’, priority=0, dont_filter=False, errback])</p>
</blockquote>
<p>myspider.py代码如下：</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MyspiderSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;myspider&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;tencent.com&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;hr.tencent.com&#x2F;position.php&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        tr_list &#x3D; response.xpath(&quot;&#x2F;&#x2F;table[@class&#x3D;&#39;tablelist&#39;]&#x2F;tr&quot;)[1:-1]</span><br><span class="line">        for tr in tr_list:</span><br><span class="line">            item&#x3D;&#123;&#125;</span><br><span class="line">            item[&quot;title&quot;] &#x3D; tr.xpath(&quot;.&#x2F;td[1]&#x2F;a&#x2F;text()&quot;).extract_first()</span><br><span class="line">            item[&quot;type&quot;] &#x3D; tr.xpath(&quot;.&#x2F;td[2]&#x2F;text()&quot;).extract_first()</span><br><span class="line">            item[&quot;position&quot;] &#x3D; tr.xpath(&quot;.&#x2F;td[4]&#x2F;text()&quot;).extract_first()</span><br><span class="line">            item[&quot;date&quot;] &#x3D; tr.xpath(&quot;.&#x2F;td[5]&#x2F;text()&quot;).extract_first()</span><br><span class="line">            yield item</span><br><span class="line"></span><br><span class="line">        #找下一页地址</span><br><span class="line">        next_url &#x3D; response.xpath(&quot;&#x2F;&#x2F;a[@id&#x3D;&#39;next&#39;]&#x2F;@href&quot;).extract_first()</span><br><span class="line">        if next_url !&#x3D; &quot;javascript:;&quot;:</span><br><span class="line">            next_url &#x3D; &quot;http:&#x2F;&#x2F;hr.tencent.com&#x2F;&quot;+next_url</span><br><span class="line">            yield scrapy.Request(</span><br><span class="line">                next_url,</span><br><span class="line">                callback&#x3D;self.parse</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>

<p>pipelines.py如下：</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"># Define your item pipelines here</span><br><span class="line">#</span><br><span class="line"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span><br><span class="line"># See: https:&#x2F;&#x2F;doc.scrapy.org&#x2F;en&#x2F;latest&#x2F;topics&#x2F;item-pipeline.html</span><br><span class="line"></span><br><span class="line">from pymongo import MongoClient</span><br><span class="line"></span><br><span class="line">client &#x3D; MongoClient(host&#x3D;&quot;127.0.0.1&quot;,port&#x3D;27017)</span><br><span class="line">collection &#x3D; client[&quot;tencent&quot;][&quot;job&quot;]</span><br><span class="line"></span><br><span class="line">class MyspidersPipeline(object):</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        print(item)</span><br><span class="line">        collection.insert(item)</span><br><span class="line">        return item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>写完之后返回命令行，运行</p>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl myspider</span><br></pre></td></tr></table></figure>

<p>程序结果，MongoDB数据库中的结果如下：</p>
<img src="/2020/01/11/scrapy%E7%88%AC%E5%8F%96%E8%85%BE%E8%AE%AF%E6%8B%9B%E8%81%98%E5%B2%97%E4%BD%8D%E5%88%B0mongoDB%E4%B8%AD/jobresult.jpg" class="" title="数据库结果">


<h2 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h2><p>scrapy这个框架极其强大，它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，这里只是用到了最基本的几个用法。之后有机会借用其他例子来更深入理解。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/11/scrapy%E7%88%AC%E5%8F%96%E8%85%BE%E8%AE%AF%E6%8B%9B%E8%81%98%E5%B2%97%E4%BD%8D%E5%88%B0mongoDB%E4%B8%AD/" data-id="ckccph4ik000by81rfxtl13e4" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Scrapy/" rel="tag">Scrapy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-多线程爬虫" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/11/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB/" class="article-date">
  <time class="post-time" datetime="2020-01-11T05:41:53.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/11/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB/">多线程爬虫</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="多线程爬取糗事百科段子"><a href="#多线程爬取糗事百科段子" class="headerlink" title="多线程爬取糗事百科段子"></a>多线程爬取糗事百科段子</h2><p>上一篇中有一个爬取糗事百科段子的demo，但是如果需要请求的url太多的情况下，一个一个请求肯定会很慢，影响效率，而且耗时主要是在网络请求中，属于IO密集型的代码，所以GIL锁在这里的影响不会很大。</p>
<p>主要用到了threading模块和queue相关的内容，而这部分内容网上一搜一大把- -不多解释。</p>
<p>以下为改写为多线程的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> html</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuibaiSpdier</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.url_temp = <span class="string">"https://www.qiushibaike.com/hot/page/&#123;&#125;/"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36"</span>&#125;</span><br><span class="line">        self.url_queue = Queue()  <span class="comment"># 需要请求的url地址</span></span><br><span class="line">        self.html_queue = Queue()</span><br><span class="line">        self.content_queue = Queue()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_url_list</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># return [self.url_temp.format(i) for i in range(1, 14)]</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">14</span>):</span><br><span class="line">            self.url_queue.put(self.url_temp.format(i))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            url = self.url_queue.get()</span><br><span class="line">            print(<span class="string">"request:"</span> + url)</span><br><span class="line">            response = requests.get(url, headers=self.headers)</span><br><span class="line">            <span class="comment"># return response.content.decode()</span></span><br><span class="line">            self.html_queue.put(response.content.decode())</span><br><span class="line">            self.url_queue.task_done()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_list</span><span class="params">(self)</span>:</span>  <span class="comment"># 提取数据</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            html_str = self.html_queue.get()</span><br><span class="line">            html_elements = html.etree.HTML(html_str)</span><br><span class="line">            div_list = html_elements.xpath(<span class="string">"//div[@id='content-left']/div"</span>)</span><br><span class="line">            content_list = []</span><br><span class="line">            <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">                item = &#123;&#125;</span><br><span class="line">                item[<span class="string">"content"</span>] = div.xpath(<span class="string">".//div[@class='content']/span/text()"</span>)</span><br><span class="line">                item[<span class="string">"author_gender"</span>] = div.xpath(<span class="string">".//div[contains(@class,'articleGender')]/@class"</span>)</span><br><span class="line">                item[<span class="string">"author_gender"</span>] = item[<span class="string">"author_gender"</span>][<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">-1</span>].replace(<span class="string">"Icon"</span>, <span class="string">""</span>) <span class="keyword">if</span> len(</span><br><span class="line">                    item[<span class="string">"author_gender"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                item[<span class="string">"content_img"</span>] = div.xpath(<span class="string">".//div[@class='thumb']/a/img/@src"</span>)</span><br><span class="line">                item[<span class="string">"content_img"</span>] = <span class="string">"https:"</span> + item[<span class="string">"content_img"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"content_img"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                item[<span class="string">"author_img"</span>] = div.xpath(<span class="string">".//div[@class='author clearfix']//img/@src"</span>)</span><br><span class="line">                item[<span class="string">"author_img"</span>] = <span class="string">"https:"</span> + item[<span class="string">"author_img"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"author_img"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                item[<span class="string">"stats_vote"</span>] = div.xpath(<span class="string">".//span[@class='stats-vote']/i/text()"</span>)</span><br><span class="line">                item[<span class="string">"stats_vote"</span>] = item[<span class="string">"stats_vote"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"stats_vote"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                content_list.append(item)</span><br><span class="line">            <span class="comment"># return content_list</span></span><br><span class="line">            self.content_queue.put(content_list)</span><br><span class="line">            self.html_queue.task_done()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_content_list</span><span class="params">(self)</span>:</span>  <span class="comment"># 保存数据</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            content_list = self.content_queue.get()</span><br><span class="line">            <span class="keyword">with</span> open(<span class="string">"qiubai.txt"</span>, <span class="string">"a"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</span><br><span class="line">                    <span class="comment"># f.write(json.dumps(content, ensure_ascii=False))</span></span><br><span class="line">                    f.write(<span class="string">"\n"</span>.join(content[<span class="string">"content"</span>]) + <span class="string">"点赞数："</span> + content[<span class="string">"stats_vote"</span>])</span><br><span class="line">                    f.write(<span class="string">"\n"</span>)</span><br><span class="line">            self.content_queue.task_done()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span>  <span class="comment"># 实现主要逻辑</span></span><br><span class="line">        thread_list = []</span><br><span class="line">        <span class="comment"># 1.构造url_list</span></span><br><span class="line">        <span class="comment"># url_list = self.get_url_list()</span></span><br><span class="line">        t_geturl = threading.Thread(target=self.get_url_list)</span><br><span class="line">        thread_list.append(t_geturl)</span><br><span class="line">        <span class="comment"># 2.遍历list，发送请求获取相应</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">7</span>):  <span class="comment"># 来7个线程来请求url地址</span></span><br><span class="line">            t_parseurl = threading.Thread(target=self.parse_url)</span><br><span class="line">            thread_list.append(t_parseurl)</span><br><span class="line">        <span class="comment"># for url in url_list:</span></span><br><span class="line">        <span class="comment"># html_str = self.parse_url(url)</span></span><br><span class="line">        <span class="comment"># 3.提取数据</span></span><br><span class="line">        <span class="comment"># content_list = self.get_content_list(html_str)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">            t_getcontent = threading.Thread(target=self.get_content_list)</span><br><span class="line">            thread_list.append(t_getcontent)</span><br><span class="line">        <span class="comment"># 4.保存数据</span></span><br><span class="line">        <span class="comment"># self.save_content_list(content_list)</span></span><br><span class="line">        t_save = threading.Thread(target=self.save_content_list)</span><br><span class="line">        thread_list.append(t_save)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">            t.setDaemon(<span class="literal">True</span>)  <span class="comment"># 子线程设置为守护线程，表示该线程不重要，主线程结束则子线程也会结束</span></span><br><span class="line">            t.start()</span><br><span class="line">        <span class="keyword">for</span> q <span class="keyword">in</span> [self.url_queue, self.html_queue, self.content_queue]:</span><br><span class="line">            q.join()  <span class="comment"># 阻塞等待子线程结束</span></span><br><span class="line">        print(<span class="string">"主线程结束"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">"qiubai.txt"</span>):</span><br><span class="line">        os.remove(<span class="string">"qiubai.txt"</span>)</span><br><span class="line">    qiubai = QuibaiSpdier()</span><br><span class="line">    qiubai.run()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/11/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB/" data-id="ckccph4ik000cy81r8zle0rff" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-爬虫基础" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" class="article-date">
  <time class="post-time" datetime="2020-01-10T15:05:33.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">爬虫基础</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>前面http和https的介绍，可直接跳过看下面的案例</p>
</blockquote>
<h2 id="HTTP与HTTPS"><a href="#HTTP与HTTPS" class="headerlink" title="HTTP与HTTPS"></a>HTTP与HTTPS</h2><p>为什么要先简要复习一下http和https？因为要发送请求，模拟浏览器，获取和浏览器一模一样的响应。</p>
<pre><code>HTTP：超文本传输协议，默认端口：80，是一种建立在TCP上的无状态连接，说白了就是个协议，规定了一些列的规则，整个基本的工作流程是客户端发送一个HTTP请求，说明客户端想要访问的资源和</code></pre><p>请求的动作，服务端收到请求之后，服务端开始处理请求，并根据请求做出相应的动作访问服务器资源,最后通过发送HTTP响应把结果返回给客户端。</p>
<pre><code>HTTPS：即HTTP+SSL（安全套接字层），默认端口号：443，即在HTTP上多了个安全套接字层SSL，SSL是一个提供数据安全和完整性的协议，负责网络连接的加密。    </code></pre><blockquote>
<p>   题外话：HTTPS通信中的几个概念：加密分为对称和非对称<br>   对称加密：信息的加密和解密都是通过同一个密钥进行的，实际通信中，一个服务器可以同时对应好几个客户端，也就是A客户端获得的加解密算法同样可以加解密B客户端<br>的消息，这跟没加密一样，为了防止这种情况，就只能不同的客户端使用不同密钥，这样的话密钥将会有很多，并且在通信刚开始，服务器和A客户端就要协商好用什么密钥，而这个协商过程是不能加密<br>的，不然A客户端就读不懂服务器消息了，因此还是存在风险。</p>
<p>   非对称加密：应用最广的加密机制“非对称加密”，特点是私钥加密后的密文，只要是公钥，都可以解密，但是反过来公钥加密后的密文，只有私钥可以解密。私钥只有一个<br>人有，而公钥可以发给所有的人。所以公钥不需要加密，而私钥只存在于服务器。这样只需要一套公钥和私钥就可以了。那么现在的问题是，如何让客户端安全的获取公钥？如果服务器直接明文发送给客户<br>端，那么可能发生被劫持的情况，例如客户端A和服务器S通信，S给A的公钥被B劫持后修改了，那么之后A将会用假的公钥进行加密，将消息发给服务器时B继续劫持，查看内容或者修改之后用真公钥加密然<br>后发给服务器，这就是中间人攻击。这时候风险依然存在，而为了解决这个问题，采用了一种SSL 证书（需要购买）和CA机构的方法，涉及防伪和证书链的概念，大概流程是：<br>   在客户端第一次请求服务器时，服务器发送回一个SSL证书给客户端，SSL 证书中包含的具体内容有<strong>证书的颁发机构的证书</strong>、有效期、<strong>公钥</strong>、证书持有者、<strong>签名</strong>。防伪的步骤：浏览器<br>拿到这个证书后读取证书中的证书所有者、有效期等信息进行一一校验，开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁<br>发，如果没找到，则报错，如果找到了，浏览器会从操作系统中取出颁发者CA的公钥，然后对服务器发来的证书里面的<strong>签名</strong>进行解密，如果能够解密则一定是证书颁发机构颁发的证书如果解密后信息<br>与Server信息一致则确实是颁发给该Server的，综上校验通过，这就是防伪的流程，而证书链的作用可以保证正在通信的Server确实是证书颁发机构指定的Server，流程是：通过和Server证书验证同<br>的过程通过内嵌在浏览器或者JDK中的根证书验证下中级证书的合法性就好了。因为根证书是内嵌的具有绝对的合法性，如果根证书信任该中级机构，则该中级证书颁发的证书也是可信的这就是证书链了。<br>这样通过第三方的校验保证了身份的合法，解决了公钥获取的安全性。什么你问我怎么申请CA证书？国内的阿里云和腾讯云上找去</p>
</blockquote>
<h2 id="举个栗子：爬取某贴吧前1000页内容"><a href="#举个栗子：爬取某贴吧前1000页内容" class="headerlink" title="举个栗子：爬取某贴吧前1000页内容"></a>举个栗子：爬取某贴吧前1000页内容</h2><p>先来一个简单的例子熟悉一下api和爬虫基本流程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TiebaSpider</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tieba_name)</span>:</span></span><br><span class="line">        self.tieba_name = tieba_name</span><br><span class="line">        self.url_temp = <span class="string">"https://tieba.baidu.com/f?kw="</span> + tieba_name + <span class="string">"&amp;ie=utf-8&amp;pn=&#123;&#125;"</span></span><br><span class="line">        self.headers=&#123;<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_url_list</span><span class="params">(self)</span>:</span>  <span class="comment">#构造url列表</span></span><br><span class="line">        <span class="comment"># url_list = []</span></span><br><span class="line">        <span class="comment"># for i in range(1000):</span></span><br><span class="line">        <span class="comment">#     url_list.append(self.url_temp.format(i*50))</span></span><br><span class="line">        <span class="comment"># return url_list</span></span><br><span class="line">        <span class="keyword">return</span> [self.url_temp.format(i*<span class="number">50</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self, url)</span>:</span>  <span class="comment">#发送请求获取相应</span></span><br><span class="line">        print(url)</span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> response.content.decode()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_html</span><span class="params">(self, html_str, page_num)</span>:</span></span><br><span class="line">        file_path = <span class="string">"&#123;&#125;第&#123;&#125;页.html"</span>.format(self.tieba_name, page_num)</span><br><span class="line">        <span class="keyword">with</span> open(file_path, <span class="string">"w"</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(html_str)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 构造url列表</span></span><br><span class="line">        url_list = self.get_url_list()</span><br><span class="line">        <span class="comment"># 遍历，发送请求，获取响应</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            html_str = self.parse_url(url)</span><br><span class="line">            page_num = url_list.index(url)+<span class="number">1</span></span><br><span class="line">            self.save_html(html_str, page_num)</span><br><span class="line">        <span class="comment"># 保存</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tieba_spider = TiebaSpider(<span class="string">"李毅"</span>)</span><br><span class="line">    tieba_spider.run()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里爬取下来的内容是没问题的，但保存下来的html直接打开是有问题的，因为万恶的百度在其中把大量有用内容添加了注释，后续是通过js来去掉注释的。这里暂时不处理，只展示基本api的使用。</p>
<h4 id="发送POST请求"><a href="#发送POST请求" class="headerlink" title="发送POST请求"></a>发送POST请求</h4><p>什么时候需要发送post请求？</p>
<ul>
<li>登录注册等有敏感信息的时候，POST比GET更安全</li>
<li>需要传输大文本的时候（POST请求对数据长度没有要求）<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response &#x3D; requests.post(&quot;&quot;,data&#x3D;data,headers&#x3D;headers)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h4><p>为什么爬虫需要代理？</p>
<ul>
<li>让服务器以为不是同一个客户端在不断请求</li>
<li>防止我们真实地址倍泄露，防止被追究</li>
</ul>
<figure class="highlight plain"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response &#x3D; requests.get(&quot;url&quot;,proxies&#x3D;proxies)</span><br></pre></td></tr></table></figure>
<p>proxies是一个字典，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">proxies=&#123;</span><br><span class="line">    <span class="string">"http"</span>:<span class="string">"http://xx.xx.xx.xx:xxx"</span>,</span><br><span class="line">    <span class="string">"https"</span>:<span class="string">"https://xx.xx.xx.xx:xxxx"</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="request模拟登陆"><a href="#request模拟登陆" class="headerlink" title="request模拟登陆"></a>request模拟登陆</h4><p>cookie和session区别：</p>
<ul>
<li>cookie数据存放在客户的浏览器上，session数据存放在服务器上</li>
<li>cookie不安全，别人可以分析存放在本地的cookie并进行cookie欺骗</li>
<li>session会在一定时间内保存在服务器上，当访问增多，会比较占用服务器性能</li>
<li>单个cookie保存的数据不能超过4k，很多浏览器会限制一个站点最多保存20个cookie</li>
</ul>
<p>1）request提供了一个session类，来实现客户端和服务器的会话保持,先实例化一个session，用session发送post请求登陆网站，把cookie保存在session中，再使用session请求登陆之后才能访问的网站，session能够自动的携带登陆成功时保存在其中的cookie。<br>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session = requests.session()</span><br><span class="line">response = session.get(url,headers)</span><br></pre></td></tr></table></figure>

<p>2）如果请求页面时不发送post请求的情况下，可以在headers中添加cookie键值对，要注意cookie的有效时间</p>
<p>3）也可以把cookie作为request的参数。此时cookie参数时一个字典。</p>
<h4 id="request小技巧"><a href="#request小技巧" class="headerlink" title="request小技巧"></a>request小技巧</h4><ul>
<li>request.utils.dict_from_cookiejar(response.cookies)  把cookie转换为字典，request.utils.cookiejar_from_dict ,将字典转化为cookie</li>
<li>request.utils.unquote(“编码后的url”)  将url地址解码，反之quote为编码</li>
<li>忽视证书错误   request.get(“url”,verify=false)</li>
<li>设置超时    request.get(“url”,timeout)</li>
<li>刷新网页 使用第三方模块retrying，还可以定义最大重新请求次数</li>
</ul>
<h2 id="爬虫的基本套路"><a href="#爬虫的基本套路" class="headerlink" title="爬虫的基本套路"></a>爬虫的基本套路</h2><ul>
<li><p>准备url</p>
<ul>
<li>准备start_url<ul>
<li>url地址规律不明显，总数不确定的情况下</li>
<li>通过代码提取下一页的url地址<ul>
<li>当下一页的地址在网页的响应中时，可以通过xpath</li>
<li>通过其他方式寻找url地址，比如通过js生成，这种情况下部分参数是在当前响应中</li>
</ul>
</li>
</ul>
</li>
<li>准备url_list<ul>
<li>页码总数明显的时候</li>
<li>url地址规律很明显</li>
</ul>
</li>
</ul>
</li>
<li><p>发送请求，获取响应</p>
<ul>
<li>添加随机的User-Agent，防反爬虫</li>
<li>添加随机的代理ip，防反爬虫</li>
<li>在对方判断出是爬虫之后，应该添加更多的header字段，包括cookies</li>
<li>cookie可以用session来解决</li>
<li>如果不登录的话<ul>
<li>准备能成功请求对方网站的cookie，即接收对方网站设置在response的cookie</li>
<li>下次请求的时候，使用之前的列表中的cookie来请求</li>
</ul>
</li>
<li>如果登录的话<ul>
<li>准备多个账号</li>
<li>获取多个账号cookie</li>
<li>之后随机选择cookie来请求登录之后才能访问的网站</li>
</ul>
</li>
</ul>
</li>
<li><p>提取数据</p>
<ul>
<li>确定数据位置，确定数据是否在当前的url地址响应中<ul>
<li>如果在当前url地址响应中<ul>
<li>提取的是列表页的数据<ul>
<li>直接请求列表页的url地址，不需要进入详情页</li>
</ul>
</li>
<li>提取的是详情页的数据<ul>
<li>1.确定详情页url地址</li>
<li>2.发送请求</li>
<li>3.提取数据</li>
<li>4.返回</li>
</ul>
</li>
</ul>
</li>
<li>如果不在当前url响应中<ul>
<li>在其他响应中，寻找数据位置</li>
</ul>
</li>
</ul>
</li>
<li>数据的提取<ul>
<li>xpath，从html中提取整块的数据，先分组，然后针对每一组进行提取</li>
<li>json</li>
<li>re，提取html中的json字符串或者某些容易用正则区分出的属性等</li>
</ul>
</li>
</ul>
</li>
<li><p>保存数据</p>
</li>
</ul>
<h2 id="一个小案例，爬去豆瓣上最近热播的英美剧，国产剧，动漫以及综艺的节目名称和评分"><a href="#一个小案例，爬去豆瓣上最近热播的英美剧，国产剧，动漫以及综艺的节目名称和评分" class="headerlink" title="一个小案例，爬去豆瓣上最近热播的英美剧，国产剧，动漫以及综艺的节目名称和评分"></a>一个小案例，爬去豆瓣上最近热播的英美剧，国产剧，动漫以及综艺的节目名称和评分</h2><p>网页截图以及爬去后的效果图如下：</p>
<img src="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/python_spider_01.jpg" class="" title="网页截图">
<img src="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/python_spider_02.jpg" class="" title="爬取后文档截图">

<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1"</span>,</span><br><span class="line">            <span class="string">"Referer"</span>: <span class="string">"https://m.douban.com/tv/american"</span>&#125;</span><br><span class="line">        self.url_temp_list = [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"url_temp"</span>: <span class="string">"https://m.douban.com/rexxar/api/v2/subject_collection/tv_american/items?start&#123;&#125;&amp;count=18&amp;loc_id=108288"</span>,</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"英美剧"</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"url_temp"</span>: <span class="string">"https://m.douban.com/rexxar/api/v2/subject_collection/tv_domestic/items?start&#123;&#125;&amp;count=18&amp;loc_id=108288"</span>,</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"国产剧"</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"url_temp"</span>: <span class="string">"https://m.douban.com/rexxar/api/v2/subject_collection/tv_animation/items?start&#123;&#125;&amp;count=18&amp;loc_id=108288"</span>,</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"动漫"</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"url_temp"</span>: <span class="string">"https://m.douban.com/rexxar/api/v2/subject_collection/tv_variety_show/items?start&#123;&#125;&amp;count=18&amp;loc_id=108288"</span>,</span><br><span class="line">                <span class="string">"type"</span>: <span class="string">"综艺"</span>,</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">        self.curIndex=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        print(url)</span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> response.content.decode()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_list</span><span class="params">(self, json_str)</span>:</span></span><br><span class="line">        dict_ret = json.loads(json_str)</span><br><span class="line">        content_list = dict_ret[<span class="string">"subject_collection_items"</span>]</span><br><span class="line">        total = dict_ret[<span class="string">"total"</span>]</span><br><span class="line">        <span class="keyword">return</span> content_list, total</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_content_list</span><span class="params">(self, content_list)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"douban.txt"</span>, <span class="string">"a"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</span><br><span class="line">                <span class="comment">#f.write(json.dumps(content, ensure_ascii=False))</span></span><br><span class="line">                f.write(self.curIndex.__str__()+<span class="string">" :"</span> + content[<span class="string">"title"</span>]+<span class="string">" 评分："</span>+content[<span class="string">"rating"</span>][<span class="string">"value"</span>].__str__())</span><br><span class="line">                f.write(<span class="string">"\n"</span>)</span><br><span class="line">                self.curIndex += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span>  <span class="comment"># 主逻辑</span></span><br><span class="line">        <span class="keyword">for</span> url_temp <span class="keyword">in</span> self.url_temp_list:</span><br><span class="line">            <span class="keyword">with</span> open(<span class="string">"douban.txt"</span>, <span class="string">"a"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(url_temp[<span class="string">"type"</span>] + <span class="string">":================================================================"</span>)  <span class="comment"># 分割线，方便数据查看</span></span><br><span class="line">                f.write(<span class="string">"\n"</span>)</span><br><span class="line">            self.curIndex = <span class="number">1</span></span><br><span class="line">            num = <span class="number">0</span></span><br><span class="line">            total = <span class="number">1</span>  <span class="comment"># 假设刚开始的条件成立</span></span><br><span class="line">            <span class="keyword">while</span> num &lt; total + <span class="number">18</span>:</span><br><span class="line">                <span class="comment"># 1.构造一个start_rul</span></span><br><span class="line">                url = url_temp[<span class="string">"url_temp"</span>].format(num)</span><br><span class="line">                <span class="comment"># 2.发送请求，获取响应</span></span><br><span class="line">                json_str = self.parse_url(url)</span><br><span class="line">                <span class="comment"># 3.提取数据，保存</span></span><br><span class="line">                content_list, total = self.get_content_list(json_str)</span><br><span class="line">                self.save_content_list(content_list)</span><br><span class="line">                <span class="comment"># if len(content_list &lt; 18):</span></span><br><span class="line">                <span class="comment">#    break</span></span><br><span class="line">                <span class="comment"># 4，构造下一页的url地址，进入2，3循环</span></span><br><span class="line">                num += <span class="number">18</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    douban = DoubanSpider()</span><br><span class="line">    douban.run()</span><br><span class="line">    print(<span class="string">"complete"</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p>2019-02-25 更新</p>
</blockquote>
<h2 id="通用案例之糗事百科段子"><a href="#通用案例之糗事百科段子" class="headerlink" title="通用案例之糗事百科段子"></a>通用案例之糗事百科段子</h2><p>作为一名段子手- -不应该只会刷段子，还要学会爬取。。<br>其中用到了 lxml模块和xpath相关内容，爬取到的信息不止有文字内容，还有图片以及作者名字和性别，但此处只在txt文档里放了段子内容。<br>效果图如下：</p>
<img src="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/qiubai_01.jpg" class="" title="网页截图">
<img src="/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/qiubai_02.jpg" class="" title="爬取后文档截图">

<p>代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuibaiSpdier</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.url_temp = <span class="string">"https://www.qiushibaike.com/hot/page/&#123;&#125;/"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_url_list</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [self.url_temp.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">14</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> response.content.decode()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_list</span><span class="params">(self, html_str)</span>:</span></span><br><span class="line">        html_elements = html.etree.HTML(html_str)</span><br><span class="line">        div_list = html_elements.xpath(<span class="string">"//div[@id='content-left']/div"</span>)</span><br><span class="line">        content_list = []</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">            item = &#123;&#125;</span><br><span class="line">            item[<span class="string">"content"</span>] = div.xpath(<span class="string">".//div[@class='content']/span/text()"</span>)</span><br><span class="line">            item[<span class="string">"author_gender"</span>] = div.xpath(<span class="string">".//div[contains(@class,'articleGender')]/@class"</span>)</span><br><span class="line">            item[<span class="string">"author_gender"</span>] = item[<span class="string">"author_gender"</span>][<span class="number">0</span>].split(<span class="string">" "</span>)[<span class="number">-1</span>].replace(<span class="string">"Icon"</span>, <span class="string">""</span>) <span class="keyword">if</span> len(</span><br><span class="line">                item[<span class="string">"author_gender"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            item[<span class="string">"content_img"</span>] = div.xpath(<span class="string">".//div[@class='thumb']/a/img/@src"</span>)</span><br><span class="line">            item[<span class="string">"content_img"</span>] = <span class="string">"https:"</span> + item[<span class="string">"content_img"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"content_img"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            item[<span class="string">"author_img"</span>] = div.xpath(<span class="string">".//div[@class='author clearfix']//img/@src"</span>)</span><br><span class="line">            item[<span class="string">"author_img"</span>] = <span class="string">"https:"</span> + item[<span class="string">"author_img"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"author_img"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            item[<span class="string">"stats_vote"</span>] = div.xpath(<span class="string">".//span[@class='stats-vote']/i/text()"</span>)</span><br><span class="line">            item[<span class="string">"stats_vote"</span>] = item[<span class="string">"stats_vote"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"stats_vote"</span>]) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            content_list.append(item)</span><br><span class="line">        <span class="keyword">return</span> content_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_content_list</span><span class="params">(self, content_list)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"qiubai.txt"</span>, <span class="string">"a"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</span><br><span class="line">                <span class="comment"># f.write(json.dumps(content, ensure_ascii=False))</span></span><br><span class="line">                f.write(<span class="string">"\n"</span>.join(content[<span class="string">"content"</span>]) + <span class="string">"点赞数："</span> + content[<span class="string">"stats_vote"</span>])</span><br><span class="line">                f.write(<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span>  <span class="comment"># 实现主要逻辑</span></span><br><span class="line">        <span class="comment"># 1.构造url_list</span></span><br><span class="line">        url_list = self.get_url_list()</span><br><span class="line">        <span class="comment"># 2.遍历list，发送请求获取相应</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            html_str = self.parse_url(url)</span><br><span class="line">            <span class="comment"># 3.提取数据</span></span><br><span class="line">            content_list = self.get_content_list(html_str)</span><br><span class="line">            <span class="comment"># 4.保存数据</span></span><br><span class="line">            self.save_content_list(content_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    qiubai = QuibaiSpdier()</span><br><span class="line">    qiubai.run()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/10/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" data-id="ckccph4in000iy81r3hg65tk0" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-python闭包" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/10/python%E9%97%AD%E5%8C%85/" class="article-date">
  <time class="post-time" datetime="2020-01-10T14:02:32.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/10/python%E9%97%AD%E5%8C%85/">python闭包</a>
    </h1>
  

        <div>
          
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a>
  </div>

          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>其实闭包是一个很简单的概念，不只是在python中有，所有把函数做为一等公民的语言均有闭包的概念。不过像Java这样以class为一等公民的语言中也可以使用闭包，只是它得用类或接口来实现。</p>
<p>虽然概念简单，但用处强大，然而这个概念却经常忘记，本着好记性不如烂笔头的想法，在这里大体概括一下闭包的基本概念，加强记忆。</p>
<h2 id="什么是闭包？"><a href="#什么是闭包？" class="headerlink" title="什么是闭包？"></a>什么是闭包？</h2><p>维基上的解释是：在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。</p>
<p>简而言之：就是函数里嵌套一个内部函数，内部函数用到了外边函数中的变量，此时内部函数和用到的外部变量组成了一块空间，这块整体空间就叫闭包。而由于在python中，函数是第一类对象可以当作返回值返回，所以这个闭包也可以当作变量传递</p>
<p>上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(myname)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span><span class="params">(hername)</span>:</span></span><br><span class="line">        print(myname, <span class="string">' and '</span>, hername)</span><br><span class="line">    <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">withwho = func(<span class="string">'pokemonlei'</span>)</span><br><span class="line">withwho(<span class="string">'qq'</span>)  <span class="comment"># &gt;&gt;&gt; pokemonlei and qq</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="闭包有什么用？"><a href="#闭包有什么用？" class="headerlink" title="闭包有什么用？"></a>闭包有什么用？</h2><ul>
<li>返回一个函数然后延迟执行</li>
<li>封装一个私有变量</li>
<li>用来实现python的装饰器等</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/10/python%E9%97%AD%E5%8C%85/" data-id="ckccph4im000gy81r6q7ue7yq" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Pokemonlei的博客</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://avatars0.githubusercontent.com/u/20333903?v=3&amp;s=460">
    <h2 class="author">pokemonlei</h2>
    <h3 class="description">陈磊的博客 | pokemonlei</h3>
    <div class="count-box">
      <a href="/archives"><div><strong>14</strong><br>文章</div></a>
      <a href="/categories"><div><strong>7</strong><br>分类</div></a>
      <a href="/tags"><div><strong>13</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://user.qzone.qq.com/1176014533/infocenter" target="_blank" title="QQZone">
          QQZone
        </a>
      
    </div>

    <div class="friend-link">
      <h2>友情链接</h2>
      
        <a class="hvr-bounce-in" href="http://blog.shanamaid.top/" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2020 - 2021 pokemonlei<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a href="https://github.com/ShanaMaid/hexo-theme-shana" target="_blank" rel="noopener">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">归档</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">占位1</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">占位2</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>